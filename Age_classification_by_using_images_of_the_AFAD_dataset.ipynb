{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Age classification by using images of the AFAD dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KfeBWXbpTxQr",
        "Xyo_3jltA9-r",
        "lfbm1hd9Bj3z",
        "go5o659CXZLv",
        "Sc41XeGrXKiZ",
        "eZuFu7p8bYIT",
        "cu0QJpQtO4Xf",
        "N_BWr2D1hXLK",
        "WRlmp8Zxh5-y",
        "aszHQa_xlvbV",
        "IeGAEnV2o4xM"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chalita20/Age-classification-by-using-the-AFAD-dataset-Internship/blob/main/Age_classification_by_using_images_of_the_AFAD_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L230C_WYTErm"
      },
      "source": [
        "reference1 : https://medium.com/analytics-vidhya/implementing-cnn-in-pytorch-with-custom-dataset-and-transfer-learning-1864daac14cc\n",
        "\n",
        "reference2 : https://nextjournal.com/gkoehler/pytorch-mnist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ax4LQSPTfwu"
      },
      "source": [
        "# Age classification by using images of the AFAD dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfeBWXbpTxQr"
      },
      "source": [
        "# ขั้นตอนการทำงาน\n",
        "\n",
        "* การเชื่อมกับ Drive เพื่อใช้ในการดึงข้อมูล\n",
        "  * การ unzip และการเข้าถึงโฟลเดอร์\n",
        "* การเตรียม Dataset \n",
        "  * การเตรียมไฟล์ csv\n",
        "  * การ import library ที่ต้องใช้ในการtrain โมเดล\n",
        "  * การแบ่ง dataset\n",
        "* การเตรียม model \n",
        "  * การสร้าง network สำหรับtrain model\n",
        "  * การtrain model\n",
        "  * การ test model\n",
        "* การทำนายผลของmodel ที่ได้\n",
        "  * การแสดงค่าAccuracy และค่าLoss\n",
        "  * การแสดงผลแบบรูปภาพ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xyo_3jltA9-r"
      },
      "source": [
        "## Mount Drive\n",
        "\n",
        "เป็นการเชื่อมต่อกับไดร์ฟเพื่อดึงข้อมูลจากไดร์ฟมาใช้งานโดยต้องเชื่อมไดร์ฟก่อนทุกครั้ง\n",
        "* เชื่อมกับไดร์ฟที่ต้องการ\n",
        "* เข้าถึงโฟลเดอร์ที่ต้องการ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjfEYuu3TDyd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb0GRuEQBXn_"
      },
      "source": [
        "%cd drive/My Drive/Colab Notebooks/Dataset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3Q-idxQC_GY"
      },
      "source": [
        "ขั้นตอนต่อไปคือจะต้องโคลนข้อมูลหรือโปรเจคที่เราต้องการใช้จากgithub มาไว้ในไดร์ฟของเรา เราจะทำการโคลนแค่ครั้งแรกตอนที่เราจะดึงข้อมูลเข้าไดร์ฟ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B94m9NWsBe1W"
      },
      "source": [
        "# !git clone https://github.com/afad-dataset/tarball-lite.git # รันแค่ครั้งแรกอย่างเดียว"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfbm1hd9Bj3z"
      },
      "source": [
        "### unzip folder images \n",
        "1. จะต้องแปลงไฟล์zip ให้เป็นไฟล์ .tar.xz \n",
        "2. จะต้องแตกไฟล์zip .tar.xz หลังจากนั้นก็สามารถดึงข้อมูลdataset จากgithubได้\n",
        "\n",
        "** โดยการแตกไฟล์จะรันแค่ครั้งแรกครั้งเดียว เพราะจะทำให้ข้อมูลซ้ำกัน **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNsBU_RpD4dv"
      },
      "source": [
        "# !cat AFAD-Lite.tar.xz* > AFAD-Lite.tar.xz # รันแค่ครั้งแรกอย่างเดียว"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CoWgU_3D66g"
      },
      "source": [
        "# !tar -xf AFAD-Lite.tar.xz # รันแค่ครั้งแรกอย่างเดียว"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1asgLTFOZS7"
      },
      "source": [
        "เข้าโฟลเดอร์รูปภาพที่แตกไฟล์ เพื่อจะดึงรูปมาใช้"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olIvjgaGBZNG"
      },
      "source": [
        "%cd ./tarball-lite/AFAD-Lite/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY-wT7I7Tz7x"
      },
      "source": [
        "## การเตรียม Dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoShZX2zT9IY"
      },
      "source": [
        "### การเตรียมไฟล์ csv\n",
        "* แบบที่ 1 แบบ labels ธรรมดา\n",
        "* แบบที่ 2 แบบOne-hot encoding\n",
        "\n",
        "\n",
        "**สามารถเลือกแบบใดแบบหนึ่งได้**\n",
        "\n",
        "ก่อนที่เราจะทำไฟล์เราจะต้องดูว่าเราเข้าโฟลเดอร์รูปภาพหรือโฟลเดอร์ที่ไฟล์เราอยู่ยังเพื่อที่จะได้ดึงข้อมูลเพราะถ้ายังไม่ได้อยู่ในโฟลเดอร์จะทำให้อาจจะหาไฟล์ไม่เจอ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7wQYbFqcxMj"
      },
      "source": [
        "การดึงข้อมูลรูปภาพที่อยู่แบบsub-folder แล้วทำเป็นไฟล์csv \n",
        "สามารถนำไฟล์csvที่ได้ไปใช้ได้เลยแต่จะมีจำนวนclassตามโฟลเดอร์ที่มีอยู่"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9Rf7auecp7S"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os,sys\n",
        "import csv\n",
        "import glob\n",
        "import os.path\n",
        "\n",
        "data_path=\"/content/drive/My Drive/Colab Notebooks/Dataset/tarball-lite/AFAD-Lite\" #ให้ใส่pathของรูปภาพที่ต้องการ\n",
        "with open('dataset_New_1.csv', 'w', newline='') as f:\n",
        "        fieldnames = ['file_name', 'age']\n",
        "        thewriter = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        thewriter.writeheader()\n",
        "        for path, dirs, files in os.walk(data_path):\n",
        "            for i in files:\n",
        "                n = os.path.join(path,i)\n",
        "                x = n.split(os.sep)\n",
        "                thewriter.writerow({'file_name': n, 'age':x[8]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go5o659CXZLv"
      },
      "source": [
        "#### แบบ labels ที่ทำเป็นแบบ 5 class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIxMVOwjYj0Z"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('dataset_New_1.csv')\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq80L8tLaX6q"
      },
      "source": [
        "df2 = df1.drop(df1.index[0])\n",
        "df3 = df2.sort_values(by='age')  # การเรียงข้อมูลตามคอลัมน์ของage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y05tCkbRalQp"
      },
      "source": [
        "z = []\n",
        "for x in df3[\"age\"]:\n",
        "  if int(x) >=18 and int(x) <=21:\n",
        "    z.append(1)\n",
        "  elif int(x) >=22 and int(x) <=25:\n",
        "    z.append(2)\n",
        "  elif int(x) >=26 and int(x) <=29:\n",
        "    z.append(3)\n",
        "  elif int(x) >=30 and int(x) <=34:\n",
        "    z.append(4)\n",
        "  elif int(x) >=35 and int(x) <=39:\n",
        "    z.append(5)\n",
        "\n",
        "df3[\"labels\"] = z\n",
        "df3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZz4YA0yanKL"
      },
      "source": [
        "df4 = df3.drop(columns='age') #ลบcolumnsที่เกินออก"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS5G-gVOawyi"
      },
      "source": [
        "df4.to_csv('New_Dataset_1.csv') #saveไฟล์csvอันใหม่"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc41XeGrXKiZ"
      },
      "source": [
        "#### แบบ One-Hot encoding ที่ทำเป็นแบบ 5 class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U3_n9iNbDk5"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('dataset_New_1.csv') #เรียกไฟล์csvจากการใส่pathและlabels ของ age\n",
        "df2 = df1.drop(df1.index[0])\n",
        "df3 = df2.sort_values(by='age')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac_yZ6osbVWB"
      },
      "source": [
        "z = []\n",
        "for x in df3[\"age\"]:\n",
        "  if int(x) >=18 and int(x) <=21:\n",
        "    z.append(1)\n",
        "  elif int(x) >=22 and int(x) <=25:\n",
        "    z.append(2)\n",
        "  elif int(x) >=26 and int(x) <=29:\n",
        "    z.append(3)\n",
        "  elif int(x) >=30 and int(x) <=34:\n",
        "    z.append(4)\n",
        "  elif int(x) >=35 and int(x) <=39:\n",
        "    z.append(5)\n",
        "\n",
        "df3[\"labels\"] = z\n",
        "df3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLK8WjbSbXIC"
      },
      "source": [
        "df4 = df3.drop(columns='age')\n",
        "cat_data = df4[['file_name']]\n",
        "num_data = df4[['labels']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuaGmZIFbjKP"
      },
      "source": [
        "top = [x for x in df4.labels.value_counts().sort_index(ascending=True).index]\n",
        "top"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbmtLnW2blaC"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "for label in top:\n",
        "  df4[label] = np.where(df4['labels']==label, 1, 0)\n",
        "\n",
        "df5 = df4[['labels']+top]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwRpnum_bqgh"
      },
      "source": [
        "df = df5.drop(columns=['labels'])\n",
        "dataset = pd.concat([cat_data, df],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEa9ZHuGbw-Z"
      },
      "source": [
        "dataset.to_csv('New_Dataset_1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZuFu7p8bYIT"
      },
      "source": [
        "### Importing Libraries \n",
        "\n",
        "ก่อนที่เราจะทำdataset เราต้องทำการ import library ที่เราจะต้องใช้งานมาด้วย"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxG0yqxvbWNb"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "import numpy as np \n",
        "\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skq85TIUg2jc"
      },
      "source": [
        "### Preparing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "241cu7ykhDRl"
      },
      "source": [
        "n_epochs = 30\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "shuffle = True\n",
        "pin_memory = True\n",
        "num_workers = 2\n",
        "\n",
        "random_seed = 1\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu0QJpQtO4Xf"
      },
      "source": [
        "#### Creating custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVn5_mOQO2g_"
      },
      "source": [
        "class FaceDataset(Dataset):\n",
        "  def __init__(self, root_dir, annotation_file, transform=None):\n",
        "    self.root_dir = root_dir\n",
        "    self.annotation = pd.read_csv(annotation_file)\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.annotation)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_id = self.annotation.iloc[index, 1]\n",
        "    img = Image.open(os.path.join(self.root_dir, str(img_id))).convert(\"RGB\")\n",
        "    y_label = self.annotation.iloc[index, 2:]\n",
        "    y_label = y_label.astype(\"float\", copy=False)\n",
        "    y_label = torch.tensor(y_label)\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "    \n",
        "    return (img, y_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_BWr2D1hXLK"
      },
      "source": [
        "#### Transformations\n",
        "\n",
        "การtransform เพื่อทำให้inputของเรามีขนาดที่ตรงตามโมเดลกำหนดได้"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m6jFH8SbTrw"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "        transforms.Resize((120, 120)),\n",
        "        # transforms.RandomCrop((299,299)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRlmp8Zxh5-y"
      },
      "source": [
        "### Setting the dataset and dataloader\n",
        "\n",
        "เป็นการแบ่งdatasetของเราเป็น 3ส่วน\n",
        "* train ใช้สำหรับการป้อนให้กับNetwork เพื่อใช้ trainโมเดล\n",
        "* validation ใช้สำหรับทดสอบหา Metries หลังจากtrainเสร็จว่าโมเดล ทำงานได้ดีแค่ไหน และเช็คแต่ละครั้งของโมเดลไหนทำงานได้ดีกว่ากัน\n",
        "* test ใช้สำหรับทดสอบหลังจากได้โมเดลที่ดีที่สุด ว่าโมเดลจะทำงานได้ดีแค่ไหนกับข้อมูลที่ไม่เคยเห็น\n",
        "\n",
        "** โดยการแบ่งจะทำการสุ่มข้อมูลออกเป็น3 ส่วนตามอัตราส่วนของข้อมูลที่เรากำหนด"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciV2XY8Ah4b8"
      },
      "source": [
        "dataset = FaceData(\"train\", \"Dataset_2.csv\", transform=transform)\n",
        "lenghts = [int(round(len(dataset)*0.7)),int(round(len(dataset)*0.2)),\n",
        "           int(round(len(dataset)*0.1))]\n",
        "train_set, validation_set, test_set = torch.utils.data.random_split(dataset, lenghts)\n",
        "train_loader = DataLoader(dataset=train_set, shuffle=shuffle,\n",
        "                          batch_size=batch_size, num_workers=num_workers,\n",
        "                          pin_memory=pin_memory)\n",
        "validation_loader = DataLoader(dataset=validation_set, shuffle=shuffle,\n",
        "                               batch_size=batch_size,num_workers=num_workers,\n",
        "                               pin_memory=pin_memory)\n",
        "test_loader = DataLoader(dataset=test_set, shuffle=shuffle,\n",
        "                          batch_size=batch_size, num_workers=num_workers,\n",
        "                          pin_memory=pin_memory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9feMqKdMk4ol"
      },
      "source": [
        "#### Examples from folder\n",
        "\n",
        "เอาไว้ลองเช็ครูปภาพในโฟลเดอร์ที่เราทำการแบ่งไว้"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZhxZBcwh1lF"
      },
      "source": [
        "examples = enumerate(test_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MZ_U9zllQKd"
      },
      "source": [
        "example_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hW_2MURlRN0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aszHQa_xlvbV"
      },
      "source": [
        "## Model\n",
        "\n",
        "การเตรียมNetworkเพื่อจะเริ่ม train model  เป็นการประกาศ class ของ network เพื่อที่จะเรียกไปใช้งานตอนtrain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMyizzfymfkj"
      },
      "source": [
        "### Building the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3eHBd02mZUi"
      },
      "source": [
        "seed=0\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnQsCa8dD4mV"
      },
      "source": [
        "สร้างคลาสของ network LeNet โดยมีโครงสร้างดังนี้\n",
        "\n",
        "* First Layer\n",
        "\t> input: (120, 120, 3) \\\n",
        "  > after padding: (124, 124, 3) \\\n",
        "  >  after convolution(kernel = 5*5): (120, 120, 16) where 124-5+1 = 120\\\n",
        "  >  after ReLU: (120, 120, 16)\\\n",
        "  >  after maxpooling(stride=2*2): (60, 60, 16) >> output \n",
        "* Second Layer\n",
        "\t> input: (60, 60, 16) \\\n",
        "\t> after convolution(kernel = 5*5): (56, 56, 32)\\\n",
        "\t> after ReLU: (56, 56, 32)\\\n",
        "\t> after maxpooling(stride=2*2): (28, 28, 32) >> output\n",
        "* Third Layer\n",
        "\t> input: (32, 28, 28)\\\n",
        "\t> after fully-connected: (120, 3)\\\n",
        "\t> after ReLU: (120, 3) > output \n",
        "* Fourth Layer\n",
        "\t> input: (120, 3)\\\n",
        "\t> after fully-connected: (84, 3)\\\n",
        "\t> after ReLU: (84, 3) > output\n",
        "* Fifth Layer\n",
        "\t  input: (84, 3)\n",
        "\n",
        "\t  after fully-connected: (5, 3)\n",
        "\t  after ReLU: (5, 3) > output\n",
        "\n",
        "> self.conv1 = nn.Conv2d(3, 16, 5, padding=2)\\\n",
        "> self.conv2 = nn.Conv2d(16, 32, 5)\\\n",
        "> self.conv3 = nn.Conv2d(32, 64, 5)\\\n",
        "> self.fc1 = nn.Linear(64*28*28, 120)\\\n",
        "> self.fc2   = nn.Linear(120, 84)\\\n",
        "> self.fc3   = nn.Linear(84, 5) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxBFvPS5m371"
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "\n",
        "    # network structure\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
        "        self.fc1   = nn.Linear(32*28*28, 120)\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        One forward pass through the network.\n",
        "        \n",
        "        Args:\n",
        "            x: input\n",
        "        '''\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
        "        x = x.view(-1, 32*28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIJZcEKq48Ct"
      },
      "source": [
        "ส่วนนี้คือการดาวน์โหลดnetworkที่ประกาศไว้มาใช้งาน \n",
        "โดย networkที่ใช้คือ LeNet (เราสามารถเรียกNetworkอื่นที่เหมาะสมกว่าได้)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfkwm1Sqm7XQ"
      },
      "source": [
        "model = LeNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWIThE-Qm-es"
      },
      "source": [
        "### Training the model\n",
        "\n",
        "การtrainโมเดลจะทำการทดสอบด้วยvalidation ทุกรอบของการtrainและจะsave model ทุกรอบของการtrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32Mx4SBOnDZF"
      },
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    for epoch in range(n_epochs):\n",
        "      training_loss = 0.0\n",
        "      val_loss = 0.0\n",
        "      val_acc = 0\n",
        "      correct_preds = 0\n",
        "      correct_train = 0\n",
        "      best_acc = 0\n",
        "      validation = 0.0\n",
        "      total = 0\n",
        "      total_train_acc = 0\n",
        "\n",
        "      loop = tqdm(enumerate(train_loader), total = len(train_loader), leave=True)\n",
        "      \n",
        "      for batch_idx, (x_imgs, y_labels) in loop:\n",
        "        x_imgs = x_imgs.to(device)\n",
        "        y_labels = y_labels.to(device)\n",
        "        outputs = model(x_imgs)\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        _, lalabel = torch.max(y_labels.data, 1)\n",
        "        correct_train += (predicted == lalabel).sum().item()\n",
        "        total_train_acc += y_labels.size(0)\n",
        "        \n",
        "        loss = criterion(outputs.float(), torch.max(y_labels, 1)[1])\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        training_loss += loss.item()\n",
        "\n",
        "      valid_data_loader = tqdm(validation_loader, total=len(validation_loader), leave=True)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        model.eval()\n",
        "        for x_imgs, y_labels in valid_data_loader:\n",
        "            x_imgs = x_imgs.to(device)\n",
        "            y_labels = y_labels.to(device)\n",
        "            outputs = model(x_imgs)\n",
        "\n",
        "            val_loss = criterion(outputs, torch.max(y_labels, 1)[1])\n",
        "            validation += val_loss.item()\n",
        "\n",
        "            total += y_labels.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            _, lalabel = torch.max(y_labels.data, 1)\n",
        "            correct_preds += (predicted == lalabel).sum().item()\n",
        "\n",
        "            torch.save(model.state_dict(), 'model_27_4_64.pth')\n",
        "            torch.save(optimizer.state_dict(), 'optimizer_27_4_64.pth')\n",
        "\n",
        "        train_acc = 100 * (correct_train / total_train_acc)\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "        validation /= len(validation_loader.dataset)\n",
        "        val_acc = 100* (correct_preds / total)\n",
        "\n",
        "        print(f'Epoch: {epoch+1}/{n_epochs}.. Training loss is: {training_loss}.. Validation Loss: {validation}')\n",
        "        print('Training Accuracy is: {:.2f}%'.format(train_acc))\n",
        "        print('Validation Accuracy is: {:.2f}%'.format(val_acc))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRtjX8a0ZMn4"
      },
      "source": [
        "### continued model\n",
        "\n",
        "เมื่อเราต้องการที่จะเทรนโมเดลต่อเราสามารถทำขั้นตอนข้างล่างต่อได้เลย โดยเป็นการเรียนweightของโมเดลที่เราเทรนไปบางส่วนแล้วมาทำการเทรนและจะมีการsave weight ใหม่ทุกๆการรันในแต่ละรอบ\n",
        "\n",
        "**โดยขั้นตอนนี้สามารถทำหรือไม่ทำก็ได้แล้วแต่ความพึงพอใจของโมเดลที่เราได้**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QILdDBjUoF-B"
      },
      "source": [
        "continued_model = LeNet().to(device)\n",
        "continued_optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZnHWHXyohyd"
      },
      "source": [
        "model_state_dict = torch.load('model_24_4_21.pth')\n",
        "continued_model.load_state_dict(model_state_dict)\n",
        "\n",
        "optimizer_state_dict = torch.load('optimizer_24_4_21.pth')\n",
        "continued_optimizer.load_state_dict(optimizer_state_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1k-53g2ojtb"
      },
      "source": [
        "def train():\n",
        "    model.eval()\n",
        "    for epoch in range(11, 20):\n",
        "      training_loss = 0.0\n",
        "      val_loss = 0.0\n",
        "      val_acc = 0\n",
        "      correct_preds = 0\n",
        "      correct_train = 0\n",
        "      best_acc = 0\n",
        "      validation = 0.0\n",
        "      total = 0\n",
        "      total_train_acc = 0\n",
        "\n",
        "      loop = tqdm(enumerate(train_loader), total = len(train_loader), leave=True)\n",
        "      \n",
        "      for batch_idx, (x_imgs, y_labels) in loop:\n",
        "        x_imgs = x_imgs.to(device)\n",
        "        y_labels = y_labels.to(device)\n",
        "        outputs = model(x_imgs)\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        _, lalabel = torch.max(y_labels.data, 1)\n",
        "        correct_train += (predicted == lalabel).sum().item()\n",
        "        total_train_acc += y_labels.size(0)\n",
        "        \n",
        "        loss = criterion(outputs.float(), torch.max(y_labels, 1)[1])\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        training_loss += loss.item()\n",
        "\n",
        "      valid_data_loader = tqdm(validation_loader, total=len(validation_loader), leave=True)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        model.eval()\n",
        "        for x_imgs, y_labels in valid_data_loader:\n",
        "            x_imgs = x_imgs.to(device)\n",
        "            y_labels = y_labels.to(device)\n",
        "            outputs = model(x_imgs)\n",
        "\n",
        "            val_loss = criterion(outputs, torch.max(y_labels, 1)[1])\n",
        "            validation += val_loss.item()\n",
        "\n",
        "            total += y_labels.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            _, lalabel = torch.max(y_labels.data, 1)\n",
        "            correct_preds += (predicted == lalabel).sum().item()\n",
        "\n",
        "            torch.save(model.state_dict(), 'model_24_4_21.pth')\n",
        "            torch.save(optimizer.state_dict(), 'optimizer_24_4_21.pth')\n",
        "\n",
        "        train_acc = 100 * (correct_train / total_train_acc)\n",
        "        training_loss /= len(train_loader.dataset)\n",
        "        validation /= len(validation_loader.dataset)\n",
        "        val_acc = 100* (correct_preds / total)\n",
        "\n",
        "        print(f'Epoch: {epoch+1}/{n_epochs}.. Training loss is: {training_loss}.. Validation Loss: {validation}')\n",
        "        print('Training Accuracy is: {:.2f}%'.format(train_acc))\n",
        "        print('Validation Accuracy is: {:.2f}%'.format(val_acc))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdT37e6UoH6j"
      },
      "source": [
        "#### test model\n",
        "\n",
        "การนำเอาโมเดลที่save แล้วมาทดสอบต่อด้วยโฟลเดอร์ของtest จึงดึงโมเดลอีกรอบ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeT1dUrwosEm"
      },
      "source": [
        "import numpy as np\n",
        "from misc import progress_bar \n",
        "\n",
        "test_loss = 0.0\n",
        "total     = 0.0\n",
        "test_correct =0.0\n",
        "\n",
        "for i, (x_imgs, y_labels) in enumerate(test_loader, 0):\n",
        "  ### Extract image and labels from trainloader\n",
        "  x_imgs  = x_imgs.to(device)\n",
        "  y_labels  = y_labels.to(device)\n",
        "\n",
        "  outputs = model(x_imgs)\n",
        "\n",
        "  loss    = criterion(outputs, torch.max(y_labels, 1)[1])\n",
        "  test_loss += loss.item()\n",
        "\n",
        "  ### select class index with the maximum value \n",
        "  total     += y_labels.size(0)\n",
        "  _, prediction = torch.max(outputs, 1)\n",
        "  _, lalabel = torch.max(y_labels, 1)\n",
        "  \n",
        "  # correct_preds += (predicted == lalabel).sum().\n",
        "  test_correct += (prediction==lalabel).sum().item()\n",
        "  progress_bar(i, len(test_loader), 'Loss: %.4f | Acc: %.3f%% (%d/%d)'\n",
        "                            % (test_loss / (i + 1), 100. * test_correct / total, test_correct, total))\n",
        "  \n",
        "\n",
        "print('test_loss = '+str(test_loss/len(test_loader.dataset)))\n",
        "print('test_accuracy = '+ str(test_correct/total))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeGAEnV2o4xM"
      },
      "source": [
        "## Prediction\n",
        "\n",
        "เป็นการเรียกแสดงผลรูปจากโฟลเดอร์ test set ว่ามีการทำนายรูปได้ถูกต้องหรือไม่โดยการแสดงผลเป็นทั้งรูปภาพและผลการทำนาย"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnetGsWFo8HN"
      },
      "source": [
        "with torch.no_grad():\n",
        "  # model.eval()\n",
        "  # exampl_data = example_data.to(device)\n",
        "  output = model(example_data.to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0oLiVCLpKpH"
      },
      "source": [
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(f'Prediction: {output.data.max(1, keepdim=True)[1][i].item()}')\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4U0Os7RYQrg"
      },
      "source": [
        "เป็นการtest รูปจากข้างนอกเพื่อดูผลความแม่นยำของModelของเราว่ามีผลที่ถูกต้องหรือไม่"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRxlIDoOpMem"
      },
      "source": [
        "model.train()\n",
        "transform = transforms.Compose([\n",
        "        transforms.Resize((120, 120)),\n",
        "        # transforms.RandomCrop((299,299)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
        "])\n",
        "\n",
        "img = Image.open('check_image.jpg')  # Load image as PIL.Image\n",
        "x = transform(img)  # Preprocess image\n",
        "x = x.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "\n",
        "output = model(x.to(device=device))  # Forward pass'\n",
        "pred = torch.argmax(output, 1)  # Get predicted class if multi-class classification\n",
        "print('Image predicted as ', pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}